{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZQhNK4HK5JGH"
      },
      "outputs": [],
      "source": [
        "\n",
        "# set up logging\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "    format=\"%(asctime)s - %(levelname)s - %(name)s -    %(message)s\",\n",
        "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "    level=logging.INFO,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make deterministic\n",
        "from utils import set_seed\n",
        "set_seed(42)\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "iPJuaUwheurq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class CharDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, block_size):\n",
        "        chars = sorted(list(set(data)))\n",
        "        data_size, vocab_size = len(data), len(chars)\n",
        "        print(f\"data has {data_size:d} characters, {vocab_size:d} unique.\")\n",
        "\n",
        "        self.stoi = { ch: i for i, ch in enumerate(chars) }\n",
        "        self.itos = { i: ch for i, ch in enumerate(chars) }\n",
        "        self.block_size = block_size\n",
        "        self.vocab_size = vocab_size\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.block_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # grab a chunk of (block_size + 1) characters from the data\n",
        "        chunk = self.data[idx:idx+self.block_size+1]\n",
        "        # encode every character to an integer\n",
        "        dix = [self.stoi[s] for s in chunk]\n",
        "\n",
        "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
        "        y = torch.tensor(dix[1:], dtype=torch.long)\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "1ZNs908Lfm03"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 128  # spacial extent of the model for its context\n",
        "# text = open('/home/grads/xiaohan/scratch/minGPT/data/The Old Man and the Sea.txt', 'r').read()\n",
        "text = open('filename.txt', 'r').read()\n",
        "train_dataset = CharDataset(text, block_size = 128) # one line of poem is roughly 50 characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yvI5elQfwIu",
        "outputId": "20097914-a104-4d22-ee8d-64710ad9ca93"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data has 43184 characters, 85 unique.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from model import GPT, GPTConfig\n",
        "\n",
        "\n",
        "mconf = GPTConfig(\n",
        "    train_dataset.vocab_size,\n",
        "    train_dataset.block_size,\n",
        "    n_layer=4,\n",
        "    n_head=8,\n",
        "    n_embd=512,\n",
        ")\n",
        "model = GPT(mconf)"
      ],
      "metadata": {
        "id": "ffd6NuLWf1U2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trainer import Trainer, TrainerConfig\n",
        "\n",
        "# initialize a trainer instance and kick off training\n",
        "tconf = TrainerConfig(\n",
        "    max_epochs=2,\n",
        "    batch_size=512,\n",
        "    learning_rate=6e-4,\n",
        "    lr_decay=True,\n",
        "    warmup_tokens=512*20,\n",
        "    final_tokens=2*len(train_dataset)*block_size,\n",
        "    num_workers=2,\n",
        ")\n",
        "trainer = Trainer(model, train_dataset, None, tconf)\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-IAkC8tgJKO",
        "outputId": "ca6bd39d-3c4e-4e20-f4da-63d0191161da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/85 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import sample\n",
        "\n",
        "context = \"Jean Valjean made his appearance\"\n",
        "x = torch.tensor([train_dataset.stoi[s] for s in context], dtype=torch.long)[None, ...].to(trainer.device)\n",
        "y = sample(model, x, 2000, temperature=1.0, sample=True, top_k=10)[0]\n",
        "completion = ''.join([train_dataset.itos[int(i)] for i in y])\n",
        "print(completion)"
      ],
      "metadata": {
        "id": "WJQWJNs9gLyH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}